{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('text_punct.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df = reviews[['business_id','text','date']]\n",
    "reviews_df = reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find the length of the review text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_length(text):\n",
    "    try:\n",
    "        val = len(text)\n",
    "    except:\n",
    "        val =0\n",
    "    return val\n",
    "# reviews_df = reviews_df.fillna('0')\n",
    "reviews_df['text_length'] = reviews_df['text'].apply(lambda x: find_length(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess the text - lowercase the review, remove punctuations other than !?, remove stop words and perform stemming__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import string\n",
    "nltk.download('stopwords')\n",
    "def load_stopwords():\n",
    "    return set(stopwords.words(\"english\"))\n",
    "main_count = 0\n",
    "def pre_process(text):\n",
    "    try:\n",
    "        global main_count\n",
    "        main_count+=1\n",
    "        count = 0\n",
    "        porter = nltk.stem.PorterStemmer()\n",
    "        text = text.lower() if len(text)>0 else text\n",
    "        remove = string.punctuation\n",
    "        remove = remove.replace(\"?\", \"\") # don't remove ?\n",
    "        remove = remove.replace(\"!\",\"\") # don't remove !\n",
    "        pattern = r\"[{}]\".format(remove)\n",
    "        text = re.sub(pattern, \" \", text)\n",
    "        words = text.split()\n",
    "        stops = load_stopwords()\n",
    "        meaningful_words = [porter.stem(w) for w in words if not w in stops]\n",
    "        if main_count%100000 == 0:\n",
    "            print(main_count)\n",
    "        return \" \".join(meaningful_words)\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "reviews_df['text'] = reviews_df['text'].apply(lambda x: pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('text_transform.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find the count of occurrence of ? and ! in the review__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['count_punctuation'] = reviews_df.text.str.count('\\?|\\!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find the sentiment score as difference between the number of positive words and negative words in the review__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('punkt')\n",
    "def find_sentiment_score(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for w in tokens:\n",
    "        if(sia.polarity_scores(w)['compound']) >= 0.5:\n",
    "            pos_count+=1\n",
    "        elif(sia.polarity_scores(w)['compound']) <= -0.5:\n",
    "            neg_count += 1\n",
    "    return pos_count - neg_count\n",
    "# reviews_df['sentiment_score'] = reviews_df['text'].apply(lambda x: find_sentiment_score(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('text_punct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>text_length</th>\n",
       "      <th>count_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5996992</th>\n",
       "      <td>5996992</td>\n",
       "      <td>abIF7pw1Hyu-eVW3LwNhyg</td>\n",
       "      <td>must admit bad experi owner staff rude busi re...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996993</th>\n",
       "      <td>5996993</td>\n",
       "      <td>fbLYRHIZAt3q839whhaBUg</td>\n",
       "      <td>worst servic experi awhil usual love oregano v...</td>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996994</th>\n",
       "      <td>5996994</td>\n",
       "      <td>b_8jCti0vuouJ_fjZpdmZw</td>\n",
       "      <td>love locat patio servic especi habanero bacon ...</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996995</th>\n",
       "      <td>5996995</td>\n",
       "      <td>wY3dlpLa0BHfDENYAPYuZA</td>\n",
       "      <td>absolut hate place would give zero star could ...</td>\n",
       "      <td>2018-04-07</td>\n",
       "      <td>792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996996</th>\n",
       "      <td>5996996</td>\n",
       "      <td>6E4i0NHTRAgpwbbRwZhlnw</td>\n",
       "      <td>first last time go mom use go sky nail harriso...</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             business_id  \\\n",
       "5996992     5996992  abIF7pw1Hyu-eVW3LwNhyg   \n",
       "5996993     5996993  fbLYRHIZAt3q839whhaBUg   \n",
       "5996994     5996994  b_8jCti0vuouJ_fjZpdmZw   \n",
       "5996995     5996995  wY3dlpLa0BHfDENYAPYuZA   \n",
       "5996996     5996996  6E4i0NHTRAgpwbbRwZhlnw   \n",
       "\n",
       "                                                      text        date  \\\n",
       "5996992  must admit bad experi owner staff rude busi re...  2016-02-29   \n",
       "5996993  worst servic experi awhil usual love oregano v...  2017-07-06   \n",
       "5996994  love locat patio servic especi habanero bacon ...  2018-04-14   \n",
       "5996995  absolut hate place would give zero star could ...  2018-04-07   \n",
       "5996996  first last time go mom use go sky nail harriso...  2018-06-07   \n",
       "\n",
       "         text_length  count_punctuation  \n",
       "5996992          320                  0  \n",
       "5996993          687                  2  \n",
       "5996994          255                  2  \n",
       "5996995          792                  3  \n",
       "5996996         1368                  4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd.Series(' '.join(('hi 1234')).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-b288bfe409f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_names = pd.Series(' '.join(reviews['text']).lower().split()).value_counts()[:1000]\n",
    "feature_names = feature_names.keys().values.tolist()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# v = TfidfVectorizer(vocabulary=feature_names)\n",
    "# x = v.fit_transform(reviews_df['text'])\n",
    "# # print(v.get_feature_names())\n",
    "# reviews_df['tfidf'] = list(x.toarray())\n",
    "# reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>text_length</th>\n",
       "      <th>count_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>love place! fianc go atleast week portion huge...</td>\n",
       "      <td>2012-11-13</td>\n",
       "      <td>317</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>terribl dri corn bread rib tip fat mushi flavo...</td>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elqbBhBfElMNSrjFqW3now</td>\n",
       "      <td>back 2005 2007 place favorit thai place ever g...</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>delici healthi food steak amaz fish pork aweso...</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgfcTvK81oD4r50NMjU2Ag</td>\n",
       "      <td>place suck custom servic horribl dont serv foo...</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AxeQEz3-s9_1TyIo-G7UQw</td>\n",
       "      <td>like thai food tri origin thai bbq pad se ew d...</td>\n",
       "      <td>2011-10-10</td>\n",
       "      <td>743</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zdE82PiD6wquvjYLyhOJNA</td>\n",
       "      <td>amazing!!! refer friend first thought korean m...</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>1190</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EAwh1OmG6t6p3nRaZOW_AA</td>\n",
       "      <td>rib amaz 2 hour wait time amaz understand plac...</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>atVh8viqTj-sqDJ35tAYVg</td>\n",
       "      <td>food pretti good gonna lie make sacrific choos...</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>995</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yFumR3CWzpfvTH2FCthvVw</td>\n",
       "      <td>emerald club member number year alway satisfi ...</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UBv8heCQR0RPnUQG0zkXIQ</td>\n",
       "      <td>score neg horribl like 6 7 item buffet naan sa...</td>\n",
       "      <td>2016-09-23</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hdgYnadxg0GANhWOJabr2g</td>\n",
       "      <td>went twice pretti happi haircut peopl realli f...</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yEOu75XjwczngvWWlr0M_A</td>\n",
       "      <td>great price 25 long hair! hesit dri cut turn g...</td>\n",
       "      <td>2016-02-17</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f5O7v_X_jCg2itqacRfxhg</td>\n",
       "      <td>sansotei serv top notch ramen take reserv comp...</td>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XqNDr54eLDLRfZwo4l4dVA</td>\n",
       "      <td>sever place get bagel oakland bagel best reall...</td>\n",
       "      <td>2015-09-22</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0bjFYstj8USMzEV4ZQldjA</td>\n",
       "      <td>cool littl place nice atmospher staff great co...</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q0n4I-zqiI47xispOqc1lA</td>\n",
       "      <td>delici friendli staff cool atmospher around gr...</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>388</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>alG1fb1kl2vmT8s34jbbHg</td>\n",
       "      <td>great haircut cool atmospher realli nice peopl...</td>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gZGsReG0VeX4uKViHTB9EQ</td>\n",
       "      <td>finally! tri mani mexican restaur thru phoenix...</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>403</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-bd4BQcl1ekgo7avaFngIw</td>\n",
       "      <td>one best breakfast place to! menu mani option ...</td>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>227</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u73j2VQ3TGWdMO-AG7MABw</td>\n",
       "      <td>food alright servic horrible! order came incor...</td>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>689</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VyVIneSU7XAWgMBllI6LnQ</td>\n",
       "      <td>delicious! forgot take pictur see amaz got 2 k...</td>\n",
       "      <td>2017-07-08</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3Mx4renubPRnjHUw1n2UkA</td>\n",
       "      <td>could leav zero star would rude b door fake la...</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>d4z4gjdhQYs-WOVClISf_A</td>\n",
       "      <td>remov sever pine tree hous henderson nv ground...</td>\n",
       "      <td>2017-06-14</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>f-v1fvtnbdw_QQRsCnwH-g</td>\n",
       "      <td>write review fractur prune first love doughnut...</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yz66FIUPDKGhILDWzRLeKg</td>\n",
       "      <td>wish could tell food problem friend went dinne...</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6qDRqHWqf0EeHupSUEBfKg</td>\n",
       "      <td>wonderful! one favorit place bbq expertli cook...</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7AlULGZI1pHt0imODsqdkg</td>\n",
       "      <td>price quizino sandwich great! live musician ki...</td>\n",
       "      <td>2012-02-12</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>th4pZ5LkoIIkb1Vmu_m2DA</td>\n",
       "      <td>food ok get lot food price bot lot seat</td>\n",
       "      <td>2012-02-12</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nsSfCKW9KDB4COj9bzXApw</td>\n",
       "      <td>staff friendli help food fabul whole experi aw...</td>\n",
       "      <td>2012-02-12</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996967</th>\n",
       "      <td>wsmVIHJEi9J_38dXx2qLKA</td>\n",
       "      <td>decent eastsid spot serv mediterranean italian...</td>\n",
       "      <td>2014-09-13</td>\n",
       "      <td>1237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996968</th>\n",
       "      <td>j1i7s55PmOFzJC3l6O8PiA</td>\n",
       "      <td>new sign say find ask spousal unit tell bob ev...</td>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996969</th>\n",
       "      <td>zjwdU1OdlbKTGjm-IfD4TQ</td>\n",
       "      <td>local beers? wisconsin restaur german restaur ...</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>1018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996970</th>\n",
       "      <td>ceuvH6NpDhpT1p4q1w93pA</td>\n",
       "      <td>new neighborhood work way park st could regula...</td>\n",
       "      <td>2011-09-12</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996971</th>\n",
       "      <td>HHCn1akqIpl_BhdcJoYPbw</td>\n",
       "      <td>time updat warm place becom weekli weekend lun...</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996972</th>\n",
       "      <td>vzqzoa-plufwTsQUwW_s6Q</td>\n",
       "      <td>pnnh make grade twice tri standard dish pho bu...</td>\n",
       "      <td>2012-05-07</td>\n",
       "      <td>585</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996973</th>\n",
       "      <td>7mjfLQctbrHXWMsxGszQlQ</td>\n",
       "      <td>new area stay friend neighborhood wait new pla...</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>1161</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996974</th>\n",
       "      <td>3-HFGxmbzSax-NySJ_LzDg</td>\n",
       "      <td>u town cold rather wait tabl crowd nearbi pho ...</td>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>1203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996975</th>\n",
       "      <td>oglIZt5mg2nErhpTH_AakQ</td>\n",
       "      <td>u way home airport hungri time zone challeng n...</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996976</th>\n",
       "      <td>OPSNdO3LNPMt7qz1MNb42g</td>\n",
       "      <td>food delici love servic eric! thank eric pan s...</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996977</th>\n",
       "      <td>CA4qhLICQWX0H_bf9iGw0Q</td>\n",
       "      <td>store mani employe check peopl go technic supp...</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996978</th>\n",
       "      <td>oJPInRXXXLwG_89I-5cIiQ</td>\n",
       "      <td>awesom servic depart ivan best friendli nice m...</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996979</th>\n",
       "      <td>JcMx_PIy0ROIlJWens4TAQ</td>\n",
       "      <td>absolut recommend place husband come californi...</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996980</th>\n",
       "      <td>gRMYm-CeEdjXtaQcVo8vsw</td>\n",
       "      <td>servic terribl parti 12 celebr birthday waitre...</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>369</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996981</th>\n",
       "      <td>WbS58nfQQZaxWk1BUPBuJQ</td>\n",
       "      <td>delici food mani healthi option choos better t...</td>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996982</th>\n",
       "      <td>hGBdtLUHanbw6rMRoMxUSQ</td>\n",
       "      <td>never hair cut person receiv previou neg revie...</td>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996983</th>\n",
       "      <td>XF7cEaCGuPkt1yuz77jeTQ</td>\n",
       "      <td>year back visit locat lawrenc love realli exci...</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>1127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996984</th>\n",
       "      <td>aLcFhMe6DDJ430zelCpd2A</td>\n",
       "      <td>plu side excel thai food good flavour balanc s...</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996985</th>\n",
       "      <td>R_fQGSUQv0L_fRiuua47dw</td>\n",
       "      <td>brought cowork boss light lunch pleasantli sur...</td>\n",
       "      <td>2018-02-21</td>\n",
       "      <td>735</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996986</th>\n",
       "      <td>rqWIntPaV8TpJvgT6H9UNw</td>\n",
       "      <td>never mad kung fu tea love product one compar ...</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996987</th>\n",
       "      <td>PwxMFnr1DJFfBjP8C9rC-A</td>\n",
       "      <td>problem health care ladi check desk talk patie...</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996988</th>\n",
       "      <td>B6qdxFg9LFff-NEVgMWRpQ</td>\n",
       "      <td>came wed dress budget time limit left feel lik...</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996989</th>\n",
       "      <td>BdzJQypceJ5Bam2P7egoiw</td>\n",
       "      <td>good food moder price custom poke bowl crab ra...</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996990</th>\n",
       "      <td>lGiUZcTvuMdx28YMvqZ2vw</td>\n",
       "      <td>husband love place go get groceri sinc live ne...</td>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996991</th>\n",
       "      <td>zr42_UsWfaIF-rcp37OpwA</td>\n",
       "      <td>food amaz smoke salmon benedict cowork pork be...</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996992</th>\n",
       "      <td>abIF7pw1Hyu-eVW3LwNhyg</td>\n",
       "      <td>must admit bad experi owner staff rude busi re...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996993</th>\n",
       "      <td>fbLYRHIZAt3q839whhaBUg</td>\n",
       "      <td>worst servic experi awhil usual love oregano v...</td>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996994</th>\n",
       "      <td>b_8jCti0vuouJ_fjZpdmZw</td>\n",
       "      <td>love locat patio servic especi habanero bacon ...</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996995</th>\n",
       "      <td>wY3dlpLa0BHfDENYAPYuZA</td>\n",
       "      <td>absolut hate place would give zero star could ...</td>\n",
       "      <td>2018-04-07</td>\n",
       "      <td>792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996996</th>\n",
       "      <td>6E4i0NHTRAgpwbbRwZhlnw</td>\n",
       "      <td>first last time go mom use go sky nail harriso...</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>1368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5996997 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    business_id  \\\n",
       "0        pomGBqfbxcqPv14c3XH-ZQ   \n",
       "1        jtQARsP6P-LbkyjbO1qNGg   \n",
       "2        elqbBhBfElMNSrjFqW3now   \n",
       "3        Ums3gaP2qM3W1XcA5r6SsQ   \n",
       "4        vgfcTvK81oD4r50NMjU2Ag   \n",
       "5        AxeQEz3-s9_1TyIo-G7UQw   \n",
       "6        zdE82PiD6wquvjYLyhOJNA   \n",
       "7        EAwh1OmG6t6p3nRaZOW_AA   \n",
       "8        atVh8viqTj-sqDJ35tAYVg   \n",
       "9        yFumR3CWzpfvTH2FCthvVw   \n",
       "10       UBv8heCQR0RPnUQG0zkXIQ   \n",
       "11       hdgYnadxg0GANhWOJabr2g   \n",
       "12       yEOu75XjwczngvWWlr0M_A   \n",
       "13       f5O7v_X_jCg2itqacRfxhg   \n",
       "14       XqNDr54eLDLRfZwo4l4dVA   \n",
       "15       0bjFYstj8USMzEV4ZQldjA   \n",
       "16       q0n4I-zqiI47xispOqc1lA   \n",
       "17       alG1fb1kl2vmT8s34jbbHg   \n",
       "18       gZGsReG0VeX4uKViHTB9EQ   \n",
       "19       -bd4BQcl1ekgo7avaFngIw   \n",
       "20       u73j2VQ3TGWdMO-AG7MABw   \n",
       "21       VyVIneSU7XAWgMBllI6LnQ   \n",
       "22       3Mx4renubPRnjHUw1n2UkA   \n",
       "23       d4z4gjdhQYs-WOVClISf_A   \n",
       "24       f-v1fvtnbdw_QQRsCnwH-g   \n",
       "25       yz66FIUPDKGhILDWzRLeKg   \n",
       "26       6qDRqHWqf0EeHupSUEBfKg   \n",
       "27       7AlULGZI1pHt0imODsqdkg   \n",
       "28       th4pZ5LkoIIkb1Vmu_m2DA   \n",
       "29       nsSfCKW9KDB4COj9bzXApw   \n",
       "...                         ...   \n",
       "5996967  wsmVIHJEi9J_38dXx2qLKA   \n",
       "5996968  j1i7s55PmOFzJC3l6O8PiA   \n",
       "5996969  zjwdU1OdlbKTGjm-IfD4TQ   \n",
       "5996970  ceuvH6NpDhpT1p4q1w93pA   \n",
       "5996971  HHCn1akqIpl_BhdcJoYPbw   \n",
       "5996972  vzqzoa-plufwTsQUwW_s6Q   \n",
       "5996973  7mjfLQctbrHXWMsxGszQlQ   \n",
       "5996974  3-HFGxmbzSax-NySJ_LzDg   \n",
       "5996975  oglIZt5mg2nErhpTH_AakQ   \n",
       "5996976  OPSNdO3LNPMt7qz1MNb42g   \n",
       "5996977  CA4qhLICQWX0H_bf9iGw0Q   \n",
       "5996978  oJPInRXXXLwG_89I-5cIiQ   \n",
       "5996979  JcMx_PIy0ROIlJWens4TAQ   \n",
       "5996980  gRMYm-CeEdjXtaQcVo8vsw   \n",
       "5996981  WbS58nfQQZaxWk1BUPBuJQ   \n",
       "5996982  hGBdtLUHanbw6rMRoMxUSQ   \n",
       "5996983  XF7cEaCGuPkt1yuz77jeTQ   \n",
       "5996984  aLcFhMe6DDJ430zelCpd2A   \n",
       "5996985  R_fQGSUQv0L_fRiuua47dw   \n",
       "5996986  rqWIntPaV8TpJvgT6H9UNw   \n",
       "5996987  PwxMFnr1DJFfBjP8C9rC-A   \n",
       "5996988  B6qdxFg9LFff-NEVgMWRpQ   \n",
       "5996989  BdzJQypceJ5Bam2P7egoiw   \n",
       "5996990  lGiUZcTvuMdx28YMvqZ2vw   \n",
       "5996991  zr42_UsWfaIF-rcp37OpwA   \n",
       "5996992  abIF7pw1Hyu-eVW3LwNhyg   \n",
       "5996993  fbLYRHIZAt3q839whhaBUg   \n",
       "5996994  b_8jCti0vuouJ_fjZpdmZw   \n",
       "5996995  wY3dlpLa0BHfDENYAPYuZA   \n",
       "5996996  6E4i0NHTRAgpwbbRwZhlnw   \n",
       "\n",
       "                                                      text        date  \\\n",
       "0        love place! fianc go atleast week portion huge...  2012-11-13   \n",
       "1        terribl dri corn bread rib tip fat mushi flavo...  2014-10-23   \n",
       "2        back 2005 2007 place favorit thai place ever g...  2011-02-25   \n",
       "3        delici healthi food steak amaz fish pork aweso...  2014-09-05   \n",
       "4        place suck custom servic horribl dont serv foo...  2011-02-25   \n",
       "5        like thai food tri origin thai bbq pad se ew d...  2011-10-10   \n",
       "6        amazing!!! refer friend first thought korean m...  2012-04-18   \n",
       "7        rib amaz 2 hour wait time amaz understand plac...  2011-02-25   \n",
       "8        food pretti good gonna lie make sacrific choos...  2012-11-09   \n",
       "9        emerald club member number year alway satisfi ...  2016-06-15   \n",
       "10       score neg horribl like 6 7 item buffet naan sa...  2016-09-23   \n",
       "11       went twice pretti happi haircut peopl realli f...  2014-08-23   \n",
       "12       great price 25 long hair! hesit dri cut turn g...  2016-02-17   \n",
       "13       sansotei serv top notch ramen take reserv comp...  2017-10-12   \n",
       "14       sever place get bagel oakland bagel best reall...  2015-09-22   \n",
       "15       cool littl place nice atmospher staff great co...  2017-01-19   \n",
       "16       delici friendli staff cool atmospher around gr...  2016-09-19   \n",
       "17       great haircut cool atmospher realli nice peopl...  2015-09-05   \n",
       "18       finally! tri mani mexican restaur thru phoenix...  2017-08-16   \n",
       "19       one best breakfast place to! menu mani option ...  2017-06-28   \n",
       "20       food alright servic horrible! order came incor...  2017-07-06   \n",
       "21       delicious! forgot take pictur see amaz got 2 k...  2017-07-08   \n",
       "22       could leav zero star would rude b door fake la...  2015-09-30   \n",
       "23       remov sever pine tree hous henderson nv ground...  2017-06-14   \n",
       "24       write review fractur prune first love doughnut...  2017-11-18   \n",
       "25       wish could tell food problem friend went dinne...  2017-11-18   \n",
       "26       wonderful! one favorit place bbq expertli cook...  2015-12-10   \n",
       "27       price quizino sandwich great! live musician ki...  2012-02-12   \n",
       "28                 food ok get lot food price bot lot seat  2012-02-12   \n",
       "29       staff friendli help food fabul whole experi aw...  2012-02-12   \n",
       "...                                                    ...         ...   \n",
       "5996967  decent eastsid spot serv mediterranean italian...  2014-09-13   \n",
       "5996968  new sign say find ask spousal unit tell bob ev...  2014-04-09   \n",
       "5996969  local beers? wisconsin restaur german restaur ...  2012-03-01   \n",
       "5996970  new neighborhood work way park st could regula...  2011-09-12   \n",
       "5996971  time updat warm place becom weekli weekend lun...  2014-01-31   \n",
       "5996972  pnnh make grade twice tri standard dish pho bu...  2012-05-07   \n",
       "5996973  new area stay friend neighborhood wait new pla...  2011-08-05   \n",
       "5996974  u town cold rather wait tabl crowd nearbi pho ...  2014-10-06   \n",
       "5996975  u way home airport hungri time zone challeng n...  2015-12-01   \n",
       "5996976  food delici love servic eric! thank eric pan s...  2017-12-23   \n",
       "5996977  store mani employe check peopl go technic supp...  2017-03-03   \n",
       "5996978  awesom servic depart ivan best friendli nice m...  2017-08-18   \n",
       "5996979  absolut recommend place husband come californi...  2017-05-26   \n",
       "5996980  servic terribl parti 12 celebr birthday waitre...  2017-03-16   \n",
       "5996981  delici food mani healthi option choos better t...  2017-07-07   \n",
       "5996982  never hair cut person receiv previou neg revie...  2017-07-07   \n",
       "5996983  year back visit locat lawrenc love realli exci...  2018-05-27   \n",
       "5996984  plu side excel thai food good flavour balanc s...  2015-10-01   \n",
       "5996985  brought cowork boss light lunch pleasantli sur...  2018-02-21   \n",
       "5996986  never mad kung fu tea love product one compar ...  2017-10-05   \n",
       "5996987  problem health care ladi check desk talk patie...  2015-10-27   \n",
       "5996988  came wed dress budget time limit left feel lik...  2017-08-01   \n",
       "5996989  good food moder price custom poke bowl crab ra...  2017-08-02   \n",
       "5996990  husband love place go get groceri sinc live ne...  2017-09-11   \n",
       "5996991  food amaz smoke salmon benedict cowork pork be...  2017-12-29   \n",
       "5996992  must admit bad experi owner staff rude busi re...  2016-02-29   \n",
       "5996993  worst servic experi awhil usual love oregano v...  2017-07-06   \n",
       "5996994  love locat patio servic especi habanero bacon ...  2018-04-14   \n",
       "5996995  absolut hate place would give zero star could ...  2018-04-07   \n",
       "5996996  first last time go mom use go sky nail harriso...  2018-06-07   \n",
       "\n",
       "         text_length  count_punctuation  \n",
       "0                317                  5  \n",
       "1                156                  0  \n",
       "2                901                  3  \n",
       "3                165                  1  \n",
       "4                467                  1  \n",
       "5                743                  4  \n",
       "6               1190                  8  \n",
       "7                337                  1  \n",
       "8                995                  3  \n",
       "9                185                  0  \n",
       "10               280                  0  \n",
       "11               117                  0  \n",
       "12                95                  2  \n",
       "13               540                  0  \n",
       "14               185                  0  \n",
       "15                80                  1  \n",
       "16               388                  3  \n",
       "17               200                  2  \n",
       "18               403                  4  \n",
       "19               227                  3  \n",
       "20               689                  2  \n",
       "21               263                  2  \n",
       "22               756                  0  \n",
       "23               218                  0  \n",
       "24               644                  0  \n",
       "25               574                  0  \n",
       "26               110                  1  \n",
       "27               139                  1  \n",
       "28                84                  0  \n",
       "29                93                  1  \n",
       "...              ...                ...  \n",
       "5996967         1237                  2  \n",
       "5996968          747                  0  \n",
       "5996969         1018                  1  \n",
       "5996970          336                  0  \n",
       "5996971          378                  1  \n",
       "5996972          585                  2  \n",
       "5996973         1161                  5  \n",
       "5996974         1203                  5  \n",
       "5996975         1180                  0  \n",
       "5996976           86                  2  \n",
       "5996977          401                  0  \n",
       "5996978          271                  0  \n",
       "5996979          312                  0  \n",
       "5996980          369                  5  \n",
       "5996981          153                  0  \n",
       "5996982          555                  1  \n",
       "5996983         1127                  0  \n",
       "5996984          187                  0  \n",
       "5996985          735                  2  \n",
       "5996986          463                  0  \n",
       "5996987          183                  0  \n",
       "5996988          566                  1  \n",
       "5996989          186                  0  \n",
       "5996990          219                  0  \n",
       "5996991          800                  1  \n",
       "5996992          320                  0  \n",
       "5996993          687                  2  \n",
       "5996994          255                  2  \n",
       "5996995          792                  3  \n",
       "5996996         1368                  4  \n",
       "\n",
       "[5996997 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.groupby('business_id')\n",
    "reviews_df.nunique()\n",
    "reviews_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_df = reviews_df.groupby(reviews_df.business_id).agg(lambda x: ' '.join(x.unique())).reset_index()\n",
    "# text_df = reviews_df.groupby('business_id')['text'].apply(lambda x: \"%s\" % ' '.join(str(x))).reset_index()\n",
    "# reviews = reviews_df.applymap(str)\n",
    "reviews = pd.read_csv('text_transform.csv', low_memory=False)\n",
    "# text_df = .groupby('business_id')['text'].apply(lambda x: ' '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id    object\n",
       "text           object\n",
       "date           object\n",
       "text_length     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.tail()\n",
    "reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews= reviews.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews['business_id'] = reviews['business_id'].astype(str)\n",
    "# text_df = reviews.groupby('business_id')['text'].apply(','.join)\n",
    "reviews['text'] = reviews['text'].astype(str)\n",
    "text_df = reviews.groupby('business_id').agg({'text': ' '.join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>mislabel food visit father nephew first orient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>real bar! great drink price short dilli drinke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>love place best new bar restaur area limit exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188593</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>real good place eat everyon friendli feel welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188594</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>guthri hand one best fast food place town neve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "188590  zzvlwkcNR1CCqOPXwuvz2A   \n",
       "188591  zzwaS0xn1MVEPEf0hNLjew   \n",
       "188592  zzwhN7x37nyjP0ZM8oiHmw   \n",
       "188593  zzwicjPC9g246MK2M1ZFBA   \n",
       "188594  zzzaIBwimxVej4tY6qFOUQ   \n",
       "\n",
       "                                                     text  \n",
       "188590  mislabel food visit father nephew first orient...  \n",
       "188591  real bar! great drink price short dilli drinke...  \n",
       "188592  love place best new bar restaur area limit exc...  \n",
       "188593  real good place eat everyon friendli feel welc...  \n",
       "188594  guthri hand one best fast food place town neve...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find the tfidf vector of the top 500 unigrams__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '15', '20', '30', '50', 'abl', 'absolut', 'actual', 'add', 'ago', 'almost', 'alreadi', 'also', 'although', 'alway', 'amaz', 'amount', 'anoth', 'anyon', 'anyth', 'appet', 'appoint', 'area', 'around', 'arriv', 'ask', 'ate', 'atmospher', 'attent', 'avail', 'averag', 'away', 'awesom', 'back', 'bacon', 'bad', 'bar', 'bartend', 'basic', 'bbq', 'bean', 'beauti', 'beef', 'beer', 'believ', 'best', 'better', 'big', 'bill', 'bit', 'bite', 'book', 'bowl', 'bread', 'breakfast', 'bring', 'brought', 'buffet', 'burger', 'busi', 'buy', 'cake', 'call', 'came', 'car', 'card', 'care', 'chang', 'charg', 'cheap', 'check', 'chees', 'chef', 'chicken', 'chip', 'chocol', 'choic', 'choos', 'clean', 'close', 'coffe', 'cold', 'come', 'comfort', 'compani', 'complet', 'cook', 'cool', 'cost', 'could', 'counter', 'coupl', 'cours', 'cream', 'crowd', 'custom', 'cut', 'day', 'de', 'deal', 'decent', 'decid', 'decor', 'definit', 'delici', 'dessert', 'differ', 'dine', 'dinner', 'disappoint', 'dish', 'dog', 'done', 'door', 'dr', 'dress', 'dri', 'drink', 'drive', 'easi', 'eat', 'egg', 'either', 'els', 'employe', 'end', 'enjoy', 'enough', 'entir', 'especi', 'etc', 'even', 'ever', 'everi', 'everyon', 'everyth', 'excel', 'except', 'expect', 'expens', 'experi', 'explain', 'extra', 'extrem', 'fact', 'famili', 'fan', 'fantast', 'far', 'fast', 'favorit', 'feel', 'felt', 'fill', 'final', 'find', 'fine', 'finish', 'first', 'fish', 'fix', 'flavor', 'floor', 'food', 'found', 'free', 'fresh', 'fri', 'friend', 'friendli', 'front', 'full', 'fun', 'game', 'gave', 'gener', 'get', 'girl', 'give', 'given', 'glass', 'go', 'good', 'got', 'great', 'green', 'grill', 'group', 'guess', 'guy', 'hair', 'half', 'hand', 'happen', 'happi', 'hard', 'head', 'help', 'high', 'highli', 'hit', 'home', 'hope', 'horribl', 'hot', 'hotel', 'hour', 'hous', 'howev', 'huge', 'husband', 'ice', 'impress', 'includ', 'incred', 'insid', 'instead', 'interest', 'issu', 'it', 'item', 'job', 'keep', 'kept', 'kid', 'kind', 'kitchen', 'know', 'knowledg', 'la', 'lack', 'ladi', 'larg', 'last', 'late', 'later', 'least', 'leav', 'left', 'less', 'let', 'life', 'light', 'like', 'line', 'list', 'littl', 'live', 'local', 'locat', 'long', 'look', 'lot', 'love', 'lunch', 'made', 'main', 'make', 'manag', 'mani', 'may', 'mayb', 'meal', 'mean', 'meat', 'mention', 'menu', 'mexican', 'might', 'min', 'mind', 'minut', 'miss', 'mix', 'money', 'month', 'morn', 'move', 'much', 'music', 'must', 'nail', 'name', 'need', 'never', 'new', 'next', 'nice', 'night', 'noodl', 'noth', 'notic', 'offer', 'offic', 'often', 'oh', 'ok', 'okay', 'old', 'one', 'onion', 'open', 'option', 'order', 'outsid', 'overal', 'owner', 'pack', 'paid', 'park', 'part', 'parti', 'past', 'patio', 'pay', 'peopl', 'perfect', 'perfectli', 'person', 'phone', 'pick', 'piec', 'pizza', 'place', 'plan', 'plate', 'play', 'pleas', 'plenti', 'plu', 'point', 'pool', 'pork', 'portion', 'potato', 'prepar', 'pretti', 'price', 'probabl', 'problem', 'product', 'profession', 'provid', 'purchas', 'put', 'qualiti', 'question', 'quick', 'quickli', 'quit', 'rate', 'read', 'readi', 'real', 'realli', 'reason', 'receiv', 'recent', 'recommend', 'red', 'regular', 'rememb', 'reserv', 'restaur', 'return', 'review', 'rib', 'rice', 'right', 'roll', 'room', 'rude', 'run', 'said', 'salad', 'sandwich', 'sat', 'saturday', 'sauc', 'saw', 'say', 'season', 'seat', 'second', 'see', 'seem', 'seen', 'select', 'serv', 'server', 'servic', 'set', 'sever', 'share', 'shop', 'short', 'show', 'shrimp', 'side', 'sign', 'sinc', 'sit', 'size', 'slow', 'small', 'someon', 'someth', 'soon', 'soup', 'space', 'special', 'spici', 'spot', 'staff', 'stand', 'star', 'start', 'stay', 'steak', 'still', 'stop', 'store', 'street', 'strip', 'stuff', 'style', 'suggest', 'super', 'sure', 'surpris', 'sushi', 'sweet', 'tabl', 'taco', 'take', 'talk', 'tast', 'tasti', 'tea', 'tell', 'terribl', 'thai', 'thank', 'thing', 'think', 'though', 'thought', 'three', 'time', 'tip', 'today', 'told', 'took', 'top', 'total', 'town', 'treat', 'tri', 'trip', 'turn', 'two', 'type', 'understand', 'us', 'use', 'usual', 'varieti', 'vega', 'view', 'visit', 'wait', 'waiter', 'waitress', 'walk', 'want', 'warm', 'watch', 'water', 'way', 'week', 'weekend', 'well', 'went', 'white', 'whole', 'wife', 'wine', 'wing', 'wish', 'without', 'wonder', 'work', 'worst', 'worth', 'would', 'wrong', 'ye', 'year', 'yelp', 'yet']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tfidf_unigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>mislabel food visit father nephew first orient...</td>\n",
       "      <td>[0.036192474321608534, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>real bar! great drink price short dilli drinke...</td>\n",
       "      <td>[0.010254887144797959, 0.012233663069688875, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>love place best new bar restaur area limit exc...</td>\n",
       "      <td>[0.016470246158228726, 0.0, 0.0, 0.01895510867...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188593</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>real good place eat everyon friendli feel welc...</td>\n",
       "      <td>[0.0270672246811142, 0.004612871088469858, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188594</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>guthri hand one best fast food place town neve...</td>\n",
       "      <td>[0.0, 0.0, 0.006869859791862968, 0.00685948966...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "188590  zzvlwkcNR1CCqOPXwuvz2A   \n",
       "188591  zzwaS0xn1MVEPEf0hNLjew   \n",
       "188592  zzwhN7x37nyjP0ZM8oiHmw   \n",
       "188593  zzwicjPC9g246MK2M1ZFBA   \n",
       "188594  zzzaIBwimxVej4tY6qFOUQ   \n",
       "\n",
       "                                                     text  \\\n",
       "188590  mislabel food visit father nephew first orient...   \n",
       "188591  real bar! great drink price short dilli drinke...   \n",
       "188592  love place best new bar restaur area limit exc...   \n",
       "188593  real good place eat everyon friendli feel welc...   \n",
       "188594  guthri hand one best fast food place town neve...   \n",
       "\n",
       "                                            tfidf_unigram  \n",
       "188590  [0.036192474321608534, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "188591  [0.010254887144797959, 0.012233663069688875, 0...  \n",
       "188592  [0.016470246158228726, 0.0, 0.0, 0.01895510867...  \n",
       "188593  [0.0270672246811142, 0.004612871088469858, 0.0...  \n",
       "188594  [0.0, 0.0, 0.006869859791862968, 0.00685948966...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(max_features=500)\n",
    "x = v.fit_transform(text_df['text'])\n",
    "print(v.get_feature_names())\n",
    "text_df['tfidf_unigram'] = list(x.toarray())\n",
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['sentiment_score'] = text_df['text'].apply(lambda x: find_sentiment_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.loc[text_df['business_id'] == '7wHLFohwCw8l6WS-feLjeg', 'tfidf'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = reviews_df.groupby('business_id').agg({'text_length': 'mean', 'count_punctuation': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = pd.read_json(\"sent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent.drop(['checkin_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188588</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188589</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>FgNgBLayRFm6H6Qr66ecbQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>tiQQqJ5ymf_XWzyF9ywArw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  pos_count  neg_count  sentiment_score\n",
       "188588  zzwhN7x37nyjP0ZM8oiHmw         41          3               38\n",
       "188589  zzwicjPC9g246MK2M1ZFBA         49         14               35\n",
       "188590  zzzaIBwimxVej4tY6qFOUQ         37          1               36\n",
       "188591  FgNgBLayRFm6H6Qr66ecbQ          0          0                0\n",
       "188592  tiQQqJ5ymf_XWzyF9ywArw          0          0                0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent['sentiment_score'] = sent['pos_count']-sent['neg_count']\n",
    "sent.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188588</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188589</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>FgNgBLayRFm6H6Qr66ecbQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>tiQQqJ5ymf_XWzyF9ywArw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  sentiment_score\n",
       "188588  zzwhN7x37nyjP0ZM8oiHmw               38\n",
       "188589  zzwicjPC9g246MK2M1ZFBA               35\n",
       "188590  zzzaIBwimxVej4tY6qFOUQ               36\n",
       "188591  FgNgBLayRFm6H6Qr66ecbQ                0\n",
       "188592  tiQQqJ5ymf_XWzyF9ywArw                0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sent.drop(['pos_count', 'neg_count'], axis=1)\n",
    "sent.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_unigram = pd.merge(df_1, text_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_unigram = pd.merge(final_df_unigram, sent, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>count_punctuation</th>\n",
       "      <th>text</th>\n",
       "      <th>tfidf_unigram</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>466.208333</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>came lunch last week pleasantli surpris fresh ...</td>\n",
       "      <td>[0.0, 0.01033006177243383, 0.0, 0.015968815752...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>785.205128</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>incred rude woman behind cashier assum own res...</td>\n",
       "      <td>[0.01860797281071805, 0.01275030573562763, 0.0...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--7zmmkVg-IMGaXbuVd0SQ</td>\n",
       "      <td>536.592593</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>great beer great place excel servic women espe...</td>\n",
       "      <td>[0.0, 0.014133100416116363, 0.0, 0.0, 0.013234...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--8LPVSo5i0Oo61X01sV9A</td>\n",
       "      <td>478.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>dr lacognata great great listen earth doctor e...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9QQLMTbFzLJ_oT-ON3Xw</td>\n",
       "      <td>436.181818</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>go particular locat sever year alway go stylis...</td>\n",
       "      <td>[0.0, 0.0, 0.042884672530692884, 0.0, 0.0, 0.0...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  text_length  count_punctuation  \\\n",
       "0  --1UhMGODdWsrMastO9DZw   466.208333           1.416667   \n",
       "1  --6MefnULPED_I942VcFNA   785.205128           1.076923   \n",
       "2  --7zmmkVg-IMGaXbuVd0SQ   536.592593           1.444444   \n",
       "3  --8LPVSo5i0Oo61X01sV9A   478.250000           0.500000   \n",
       "4  --9QQLMTbFzLJ_oT-ON3Xw   436.181818           1.636364   \n",
       "\n",
       "                                                text  \\\n",
       "0  came lunch last week pleasantli surpris fresh ...   \n",
       "1  incred rude woman behind cashier assum own res...   \n",
       "2  great beer great place excel servic women espe...   \n",
       "3  dr lacognata great great listen earth doctor e...   \n",
       "4  go particular locat sever year alway go stylis...   \n",
       "\n",
       "                                       tfidf_unigram  sentiment_score  \n",
       "0  [0.0, 0.01033006177243383, 0.0, 0.015968815752...               20  \n",
       "1  [0.01860797281071805, 0.01275030573562763, 0.0...               27  \n",
       "2  [0.0, 0.014133100416116363, 0.0, 0.0, 0.013234...               50  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                0  \n",
       "4  [0.0, 0.0, 0.042884672530692884, 0.0, 0.0, 0.0...                7  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_unigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "final_df_unigram.to_csv('unigram_1.csv')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "n_grams = vectorizer.fit_transform(reviews_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "count_values = n_grams.toarray().sum(axis=0)\n",
    "counts = sorted([(count_values[i],k) for k,i in vocab.items()], reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(x[1] for x in counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find tfidf for top 500 bigrams__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-390174df2ac7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tfidf_bigram'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[0mn_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[1;34m(self, X, vocabulary)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mmap_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mold_val\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'clip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(ngram_range=(2,2), max_features=500)\n",
    "x = v.fit_transform(text_df['text'])\n",
    "print(v.get_feature_names())\n",
    "text_df['tfidf_bigram'] = list(x.toarray())\n",
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_bigram = pd.merge(df_1, text_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_bigram=pd.merge(final_df_bigram, sent, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_bigram.to_csv('bigram_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tfidf_unigram</th>\n",
       "      <th>tfidf_bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>mislabel food visit father nephew first orient...</td>\n",
       "      <td>[0.036192474321608534, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>real bar! great drink price short dilli drinke...</td>\n",
       "      <td>[0.010254887144797959, 0.012233663069688875, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.10710779024989567, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>love place best new bar restaur area limit exc...</td>\n",
       "      <td>[0.016470246158228726, 0.0, 0.0, 0.01895510867...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188593</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>real good place eat everyon friendli feel welc...</td>\n",
       "      <td>[0.0270672246811142, 0.004612871088469858, 0.0...</td>\n",
       "      <td>[0.0361642436159369, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188594</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>guthri hand one best fast food place town neve...</td>\n",
       "      <td>[0.0, 0.0, 0.006869859791862968, 0.00685948966...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.03822166549927315,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "188590  zzvlwkcNR1CCqOPXwuvz2A   \n",
       "188591  zzwaS0xn1MVEPEf0hNLjew   \n",
       "188592  zzwhN7x37nyjP0ZM8oiHmw   \n",
       "188593  zzwicjPC9g246MK2M1ZFBA   \n",
       "188594  zzzaIBwimxVej4tY6qFOUQ   \n",
       "\n",
       "                                                     text  \\\n",
       "188590  mislabel food visit father nephew first orient...   \n",
       "188591  real bar! great drink price short dilli drinke...   \n",
       "188592  love place best new bar restaur area limit exc...   \n",
       "188593  real good place eat everyon friendli feel welc...   \n",
       "188594  guthri hand one best fast food place town neve...   \n",
       "\n",
       "                                            tfidf_unigram  \\\n",
       "188590  [0.036192474321608534, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "188591  [0.010254887144797959, 0.012233663069688875, 0...   \n",
       "188592  [0.016470246158228726, 0.0, 0.0, 0.01895510867...   \n",
       "188593  [0.0270672246811142, 0.004612871088469858, 0.0...   \n",
       "188594  [0.0, 0.0, 0.006869859791862968, 0.00685948966...   \n",
       "\n",
       "                                             tfidf_bigram  \n",
       "188590  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "188591  [0.0, 0.0, 0.0, 0.10710779024989567, 0.0, 0.0,...  \n",
       "188592  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "188593  [0.0361642436159369, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "188594  [0.0, 0.0, 0.0, 0.0, 0.0, 0.03822166549927315,...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('bigram_unigram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.read_csv('text_transform.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(['text_length'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['text'] = reviews['text'].astype(str)\n",
    "text_df = reviews.groupby('business_id').agg({'text': ' '.join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '10', '100', '11', '12', '15', '20', '24', '25', '30', '40', '45', '50', '99', 'abl', 'absolut', 'accommod', 'across', 'actual', 'ad', 'add', 'addit', 'afford', 'afternoon', 'again', 'ago', 'agre', 'ahead', 'air', 'airport', 'allow', 'almost', 'alon', 'along', 'alreadi', 'also', 'although', 'alway', 'amaz', 'amazing', 'ambianc', 'american', 'amount', 'annoy', 'anoth', 'answer', 'anyon', 'anyth', 'anyway', 'anywher', 'apart', 'apolog', 'app', 'appar', 'appear', 'appet', 'appl', 'appoint', 'appreci', 'area', 'around', 'arriv', 'art', 'asian', 'ask', 'ate', 'atmospher', 'attend', 'attent', 'attitud', 'authent', 'avail', 'averag', 'avocado', 'avoid', 'aw', 'away', 'awesom', 'awesome', 'babi', 'back', 'bacon', 'bad', 'bag', 'bake', 'ball', 'bar', 'bare', 'bartend', 'base', 'basic', 'bathroom', 'bbq', 'bean', 'beat', 'beauti', 'becom', 'bed', 'beef', 'beer', 'begin', 'behind', 'believ', 'best', 'better', 'beyond', 'big', 'bill', 'birthday', 'bit', 'bite', 'black', 'bland', 'blue', 'board', 'book', 'booth', 'bother', 'bottl', 'bottom', 'bought', 'bowl', 'box', 'boy', 'boyfriend', 'brand', 'bread', 'break', 'breakfast', 'bring', 'broth', 'brought', 'brown', 'brunch', 'buck', 'buffet', 'build', 'bun', 'bunch', 'burger', 'burrito', 'busi', 'butter', 'buy', 'cafe', 'cake', 'call', 'came', 'cannot', 'car', 'card', 'care', 'carri', 'case', 'cash', 'cashier', 'casino', 'casual', 'caus', 'center', 'certainli', 'chain', 'chair', 'chanc', 'chang', 'charg', 'cheap', 'check', 'chees', 'chef', 'chicken', 'chili', 'chines', 'chip', 'chocol', 'choic', 'choos', 'chose', 'citi', 'class', 'classic', 'clean', 'clear', 'clearli', 'close', 'cloth', 'club', 'cocktail', 'coffe', 'cold', 'color', 'combin', 'combo', 'come', 'comfort', 'commun', 'compani', 'compar', 'complain', 'complaint', 'complet', 'concern', 'consid', 'consist', 'contact', 'continu', 'conveni', 'convers', 'cook', 'cooki', 'cool', 'corn', 'corner', 'cost', 'could', 'counter', 'coupl', 'coupon', 'cours', 'cover', 'crab', 'crave', 'crazi', 'cream', 'creami', 'credit', 'crispi', 'crowd', 'crust', 'cup', 'curri', 'custom', 'cut', 'cute', 'danc', 'dark', 'date', 'daughter', 'day', 'de', 'deal', 'decent', 'decid', 'decor', 'deep', 'definit', 'delici', 'delicious', 'deliv', 'deliveri', 'desert', 'design', 'desk', 'despit', 'dessert', 'detail', 'die', 'differ', 'dine', 'diner', 'dinner', 'dip', 'dirti', 'disappoint', 'discount', 'dish', 'doctor', 'dog', 'dollar', 'done', 'donut', 'door', 'doubl', 'downtown', 'dr', 'dress', 'dri', 'drink', 'drive', 'drop', 'duck', 'due', 'earli', 'easi', 'easili', 'eat', 'eaten', 'effici', 'egg', 'either', 'els', 'elsewher', 'email', 'employe', 'empti', 'end', 'enjoy', 'enough', 'enter', 'entir', 'entre', 'environ', 'especi', 'establish', 'et', 'etc', 'even', 'event', 'ever', 'everi', 'everyon', 'everyth', 'exactli', 'excel', 'except', 'excit', 'expect', 'expens', 'experi', 'experienc', 'explain', 'extra', 'extrem', 'eye', 'face', 'fact', 'fair', 'fairli', 'fall', 'famili', 'fan', 'fanci', 'fantast', 'far', 'fast', 'favorit', 'fee', 'feel', 'felt', 'figur', 'fill', 'final', 'find', 'fine', 'finish', 'first', 'fish', 'fit', 'five', 'fix', 'flavor', 'flavour', 'flight', 'floor', 'follow', 'food', 'forget', 'forgot', 'forward', 'found', 'four', 'free', 'french', 'frequent', 'fresh', 'fri', 'friday', 'friend', 'friendli', 'front', 'frozen', 'fruit', 'full', 'fun', 'futur', 'game', 'garlic', 'gave', 'gem', 'gener', 'get', 'gift', 'girl', 'give', 'given', 'glad', 'glass', 'go', 'goe', 'gone', 'good', 'got', 'gotten', 'grab', 'greasi', 'great', 'green', 'greet', 'grill', 'group', 'groupon', 'guess', 'guest', 'guy', 'gym', 'hair', 'half', 'hand', 'handl', 'hang', 'happen', 'happi', 'hard', 'hate', 'head', 'healthi', 'hear', 'heard', 'heart', 'heat', 'help', 'here', 'high', 'highli', 'hit', 'hold', 'home', 'homemad', 'honest', 'honestli', 'hope', 'horribl', 'hostess', 'hot', 'hotel', 'hour', 'hous', 'howev', 'huge', 'hungri', 'husband', 'ice', 'idea', 'imagin', 'immedi', 'import', 'impress', 'improv', 'includ', 'incred', 'indian', 'inform', 'ingredi', 'insid', 'instal', 'instead', 'insur', 'interest', 'issu', 'it', 'italian', 'item', 'japanes', 'job', 'joint', 'juic', 'juici', 'keep', 'kept', 'key', 'kick', 'kid', 'kind', 'kinda', 'kitchen', 'knew', 'know', 'knowledg', 'korean', 'la', 'lack', 'ladi', 'lamb', 'larg', 'last', 'late', 'later', 'le', 'learn', 'least', 'leav', 'left', 'lemon', 'less', 'let', 'lettuc', 'level', 'life', 'light', 'like', 'limit', 'line', 'list', 'listen', 'liter', 'littl', 'live', 'lobster', 'local', 'locat', 'lol', 'long', 'longer', 'look', 'lost', 'lot', 'loud', 'love', 'low', 'lunch', 'mac', 'machin', 'made', 'main', 'make', 'mall', 'man', 'manag', 'mani', 'margarita', 'market', 'massag', 'matter', 'may', 'mayb', 'meal', 'mean', 'meat', 'mediocr', 'medium', 'meet', 'melt', 'member', 'mention', 'menu', 'mess', 'met', 'mexican', 'middl', 'might', 'mile', 'milk', 'min', 'mind', 'mine', 'minut', 'miss', 'mistak', 'mix', 'modern', 'mom', 'monday', 'money', 'month', 'morn', 'mostli', 'mouth', 'move', 'movi', 'much', 'multipl', 'mushroom', 'music', 'must', 'nail', 'name', 'near', 'need', 'neg', 'neighborhood', 'never', 'new', 'next', 'nice', 'night', 'non', 'none', 'noodl', 'normal', 'notch', 'note', 'noth', 'notic', 'number', 'obvious', 'offer', 'offic', 'often', 'oh', 'oil', 'ok', 'okay', 'old', 'one', 'onion', 'onlin', 'open', 'opinion', 'option', 'order', 'organ', 'origin', 'other', 'otherwis', 'outdoor', 'outsid', 'outstand', 'overal', 'overpr', 'owner', 'pack', 'pad', 'paid', 'pain', 'pair', 'pancak', 'paper', 'park', 'part', 'parti', 'pass', 'past', 'pasta', 'patient', 'patio', 'pay', 'peopl', 'pepper', 'per', 'perfect', 'perfectli', 'person', 'pho', 'phoenix', 'phone', 'photo', 'pick', 'pictur', 'pie', 'piec', 'pizza', 'place', 'plan', 'plate', 'play', 'pleas', 'pleasant', 'plenti', 'plu', 'pm', 'point', 'polit', 'pool', 'poor', 'pop', 'pork', 'portion', 'posit', 'possibl', 'post', 'potato', 'pour', 'prefer', 'prepar', 'present', 'pretti', 'previou', 'price', 'pricey', 'probabl', 'problem', 'process', 'product', 'profession', 'provid', 'pull', 'purchas', 'put', 'qualiti', 'question', 'quick', 'quickli', 'quiet', 'quit', 'quot', 'ramen', 'rang', 'rare', 'rate', 'rather', 'read', 'readi', 'real', 'realiz', 'realli', 'reason', 'receiv', 'recent', 'recommend', 'red', 'refil', 'regular', 'relax', 'rememb', 'remind', 'remov', 'repair', 'replac', 'request', 'reserv', 'respons', 'rest', 'restaur', 'result', 'return', 'review', 'rib', 'rice', 'rich', 'ride', 'ridicul', 'right', 'ring', 'roast', 'rock', 'roll', 'room', 'rude', 'run', 'rush', 'sad', 'said', 'salad', 'sale', 'salmon', 'salon', 'salsa', 'salt', 'salti', 'sampl', 'sandwich', 'sat', 'satisfi', 'saturday', 'sauc', 'sausag', 'save', 'saw', 'say', 'schedul', 'school', 'scottsdal', 'seafood', 'season', 'seat', 'second', 'section', 'see', 'seem', 'seen', 'select', 'sell', 'send', 'sent', 'serious', 'serv', 'server', 'servic', 'service', 'set', 'sever', 'share', 'shop', 'short', 'shot', 'show', 'shrimp', 'side', 'sign', 'similar', 'simpl', 'simpli', 'sinc', 'singl', 'sit', 'situat', 'size', 'skin', 'slice', 'slightli', 'slow', 'small', 'smaller', 'smell', 'smile', 'smoke', 'snack', 'soft', 'solid', 'someon', 'someth', 'sometim', 'somewher', 'son', 'soon', 'sorri', 'sort', 'sound', 'soup', 'sour', 'spa', 'space', 'speak', 'special', 'specif', 'spend', 'spent', 'spice', 'spici', 'split', 'sport', 'spot', 'spring', 'staff', 'stand', 'standard', 'star', 'start', 'state', 'station', 'stay', 'steak', 'step', 'stick', 'still', 'stop', 'store', 'stori', 'strawberri', 'street', 'strip', 'stuf', 'stuff', 'style', 'suck', 'sugar', 'suggest', 'suit', 'summer', 'sunday', 'super', 'suppos', 'sure', 'surpris', 'sushi', 'sweet', 'system', 'tabl', 'taco', 'take', 'taken', 'talk', 'tast', 'tasti', 'tea', 'team', 'tell', 'tender', 'terribl', 'textur', 'thai', 'thank', 'that', 'thick', 'thin', 'thing', 'think', 'though', 'thought', 'three', 'throughout', 'ticket', 'time', 'tini', 'tip', 'tire', 'toast', 'today', 'togeth', 'told', 'tomato', 'ton', 'tonight', 'too', 'took', 'top', 'toronto', 'total', 'touch', 'town', 'tradit', 'train', 'travel', 'treat', 'tri', 'trip', 'truck', 'true', 'truli', 'trust', 'tuna', 'turn', 'tv', 'twice', 'two', 'type', 'typic', 'understand', 'unfortun', 'uniqu', 'unless', 'updat', 'upon', 'us', 'use', 'usual', 'valley', 'valu', 'varieti', 'vega', 'vegan', 'veget', 'vegetarian', 'veggi', 'vehicl', 'vibe', 'view', 'visit', 'waffl', 'wait', 'waiter', 'waitress', 'walk', 'wall', 'want', 'warm', 'wash', 'wast', 'watch', 'water', 'way', 'websit', 'wed', 'week', 'weekend', 'weird', 'welcom', 'well', 'went', 'whatev', 'white', 'whole', 'wife', 'window', 'wine', 'wing', 'wish', 'within', 'without', 'woman', 'wonder', 'word', 'work', 'worker', 'world', 'wors', 'worst', 'worth', 'would', 'wow', 'wrap', 'write', 'wrong', 'ye', 'year', 'yelp', 'yet', 'young', 'yum', 'yummi']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>...</th>\n",
       "      <th>wrap</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>mislabel food visit father nephew first orient...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>real bar! great drink price short dilli drinke...</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.034423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.029312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>love place best new bar restaur area limit exc...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>0.019976</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188593</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>real good place eat everyon friendli feel welc...</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.026134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.012271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188594</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>guthri hand one best fast food place town neve...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "188590  zzvlwkcNR1CCqOPXwuvz2A   \n",
       "188591  zzwaS0xn1MVEPEf0hNLjew   \n",
       "188592  zzwhN7x37nyjP0ZM8oiHmw   \n",
       "188593  zzwicjPC9g246MK2M1ZFBA   \n",
       "188594  zzzaIBwimxVej4tY6qFOUQ   \n",
       "\n",
       "                                                     text        00        10  \\\n",
       "188590  mislabel food visit father nephew first orient...  0.000000  0.031995   \n",
       "188591  real bar! great drink price short dilli drinke...  0.007264  0.009955   \n",
       "188592  love place best new bar restaur area limit exc...  0.000000  0.015633   \n",
       "188593  real good place eat everyon friendli feel welc...  0.010897  0.026134   \n",
       "188594  guthri hand one best fast food place town neve...  0.000000  0.000000   \n",
       "\n",
       "             100        11        12        15        20   24    ...     wrap  \\\n",
       "188590  0.000000  0.049459  0.000000  0.000000  0.000000  0.0    ...      0.0   \n",
       "188591  0.007199  0.007695  0.000000  0.011876  0.034423  0.0    ...      0.0   \n",
       "188592  0.000000  0.000000  0.010979  0.000000  0.000000  0.0    ...      0.0   \n",
       "188593  0.000000  0.000000  0.005244  0.004454  0.008606  0.0    ...      0.0   \n",
       "188594  0.000000  0.000000  0.000000  0.000000  0.006400  0.0    ...      0.0   \n",
       "\n",
       "        write     wrong        ye      year      yelp       yet     young  \\\n",
       "188590    0.0  0.000000  0.040883  0.000000  0.000000  0.000000  0.000000   \n",
       "188591    0.0  0.005868  0.006360  0.029312  0.000000  0.000000  0.014919   \n",
       "188592    0.0  0.018431  0.019976  0.019727  0.010069  0.018943  0.000000   \n",
       "188593    0.0  0.004402  0.028623  0.025126  0.000000  0.009048  0.005595   \n",
       "188594    0.0  0.006546  0.007095  0.004671  0.014306  0.006729  0.000000   \n",
       "\n",
       "           yum     yummi  \n",
       "188590  0.0000  0.000000  \n",
       "188591  0.0000  0.000000  \n",
       "188592  0.0000  0.000000  \n",
       "188593  0.0069  0.012271  \n",
       "188594  0.0000  0.000000  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(max_features=1000)\n",
    "x = v.fit_transform(text_df['text'])\n",
    "print(v.get_feature_names())\n",
    "df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names())\n",
    "# text_df['tfidf_unigram'] = pd.dataframe(x.toarray())\n",
    "res = pd.concat([text_df, df1], axis=1)\n",
    "res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('tfidf_unigram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>...</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>WiFi</th>\n",
       "      <th>Music</th>\n",
       "      <th>Ambience</th>\n",
       "      <th>BusinessParking</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>checkin_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>count_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188588</th>\n",
       "      <td>188588</td>\n",
       "      <td>sMQAZ3DkfrURFoJAyOhjEw</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.551152</td>\n",
       "      <td>-80.021213</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>534.222222</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188589</th>\n",
       "      <td>188589</td>\n",
       "      <td>6hvuCibNS4uECetHb9MCQQ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.534242</td>\n",
       "      <td>-80.019556</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>810.600000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>188590</td>\n",
       "      <td>KleCXFYOmdACcQUvf6_XEg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.378669</td>\n",
       "      <td>-80.724733</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>547</td>\n",
       "      <td>631.846154</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>188591</td>\n",
       "      <td>3_fIsSxN2RBovQ_6EFtLzA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.364366</td>\n",
       "      <td>-80.703454</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>788.789474</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>188592</td>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.118697</td>\n",
       "      <td>-115.154270</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>568.500000</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             business_id  stars   latitude   longitude  \\\n",
       "188588      188588  sMQAZ3DkfrURFoJAyOhjEw    2.5  40.551152  -80.021213   \n",
       "188589      188589  6hvuCibNS4uECetHb9MCQQ    2.0  40.534242  -80.019556   \n",
       "188590      188590  KleCXFYOmdACcQUvf6_XEg    3.0  35.378669  -80.724733   \n",
       "188591      188591  3_fIsSxN2RBovQ_6EFtLzA    4.0  35.364366  -80.703454   \n",
       "188592      188592  NkOvIueadjFUxeCyq_uQEw    4.0  36.118697 -115.154270   \n",
       "\n",
       "        review_count  is_open  Monday  Tuesday  Wednesday        ...          \\\n",
       "188588             9        0       1        1          1        ...           \n",
       "188589             5        1       0        0          0        ...           \n",
       "188590            26        1       1        1          1        ...           \n",
       "188591            19        1       1        1          1        ...           \n",
       "188592             8        1       0        1          1        ...           \n",
       "\n",
       "        Alcohol  WiFi  Music  Ambience  BusinessParking  pos_count  neg_count  \\\n",
       "188588        0     0      0         0                0          4          5   \n",
       "188589        0     0      0         0                0          1          4   \n",
       "188590        0     0      0         0                4         20          6   \n",
       "188591        0     1      0         0                0         17          2   \n",
       "188592        0     0      0         0                4          6          2   \n",
       "\n",
       "        checkin_count  text_length  count_punctuation  \n",
       "188588              3   534.222222           2.000000  \n",
       "188589              0   810.600000           0.200000  \n",
       "188590            547   631.846154           0.769231  \n",
       "188591             58   788.789474           1.000000  \n",
       "188592             14   568.500000           2.375000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_dataset.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.merge(df,res,on='business_id').to_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 500 unigram and 500 bigrams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_transform.csv should contain only business_id and text as its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done--\n",
      "generate unigram\n",
      "['10', 'actual', 'also', 'alway', 'amaz', 'anoth', 'area', 'around', 'ask', 'away', 'awesom', 'back', 'bad', 'bar', 'beer', 'best', 'better', 'big', 'bit', 'burger', 'busi', 'call', 'came', 'car', 'care', 'check', 'chees', 'chicken', 'clean', 'close', 'coffe', 'come', 'cook', 'could', 'custom', 'day', 'decid', 'definit', 'delici', 'differ', 'dinner', 'disappoint', 'dish', 'done', 'drink', 'eat', 'end', 'enjoy', 'enough', 'even', 'ever', 'everi', 'everyth', 'excel', 'expect', 'experi', 'famili', 'favorit', 'feel', 'find', 'first', 'flavor', 'food', 'found', 'free', 'fresh', 'fri', 'friend', 'friendli', 'full', 'get', 'give', 'go', 'good', 'got', 'great', 'guy', 'happi', 'help', 'home', 'hot', 'hotel', 'hour', 'howev', 'item', 'kind', 'know', 'last', 'left', 'let', 'like', 'line', 'littl', 'locat', 'long', 'look', 'lot', 'love', 'lunch', 'made', 'make', 'manag', 'mani', 'meal', 'meat', 'menu', 'minut', 'much', 'need', 'never', 'new', 'next', 'nice', 'night', 'noth', 'offer', 'one', 'open', 'option', 'order', 'overal', 'park', 'pay', 'peopl', 'perfect', 'person', 'pizza', 'place', 'pretti', 'price', 'put', 'qualiti', 'realli', 'reason', 'recommend', 'restaur', 'review', 'rice', 'right', 'roll', 'room', 'said', 'salad', 'sandwich', 'sauc', 'say', 'seat', 'see', 'seem', 'select', 'serv', 'server', 'servic', 'shop', 'show', 'side', 'sinc', 'small', 'someth', 'special', 'spot', 'staff', 'star', 'start', 'stay', 'still', 'stop', 'store', 'super', 'sure', 'sweet', 'tabl', 'take', 'tast', 'tell', 'thank', 'thing', 'think', 'though', 'time', 'told', 'took', 'top', 'tri', 'two', 'us', 'use', 'vega', 'visit', 'wait', 'walk', 'want', 'way', 'week', 'well', 'went', 'work', 'worth', 'would', 'year']\n",
      "generate bigram\n",
      "['10 minut', '15 minut', '20 minut', '30 minut', '45 minut', 'absolut love', 'across street', 'also order', 'alway get', 'alway good', 'alway great', 'answer question', 'back tri', 'best ever', 'best part', 'call back', 'came back', 'come back', 'could get', 'credit card', 'custom servic', 'decid tri', 'definit back', 'definit come', 'definit go', 'definit recommend', 'definit worth', 'dine experi', 'drink order', 'drive thru', 'even better', 'even though', 'everi time', 'excel servic', 'fast food', 'feel like', 'felt like', 'first time', 'first visit', 'five star', 'food alway', 'food amaz', 'food came', 'food delici', 'food drink', 'food good', 'food great', 'food order', 'food realli', 'food servic', 'french toast', 'fri chicken', 'fri rice', 'friday night', 'friendli help', 'friendli servic', 'friendli staff', 'front desk', 'gave us', 'get food', 'give place', 'give star', 'give tri', 'gluten free', 'go back', 'go get', 'go place', 'go wrong', 'good food', 'good place', 'good price', 'good servic', 'good thing', 'good time', 'great custom', 'great experi', 'great food', 'great job', 'great place', 'great price', 'great servic', 'great time', 'happi hour', 'help us', 'highli recommend', 'ice cream', 'la vega', 'last night', 'last time', 'late night', 'let know', 'like place', 'littl bit', 'long time', 'look forward', 'look good', 'look great', 'look like', 'love it', 'love love', 'love place', 'mac chees', 'made sure', 'make feel', 'make sure', 'mani time', 'mash potato', 'mexican food', 'minut later', 'much better', 'never go', 'new york', 'next day', 'next door', 'next time', 'nice place', 'noth special', 'one best', 'one favorit', 'one star', 'one thing', 'one time', 'order food', 'pad thai', 'park lot', 'place eat', 'place get', 'place go', 'place good', 'place great', 'place like', 'place order', 'portion size', 'pretti good', 'pretti much', 'price reason', 'qualiti food', 'read review', 'realli enjoy', 'realli good', 'realli great', 'realli like', 'realli nice', 'realli want', 'reason price', 'recommend anyon', 'recommend place', 'right away', 'said would', 'saturday night', 'second time', 'seem like', 'servic alway', 'servic excel', 'servic food', 'servic friendli', 'servic good', 'servic great', 'sever time', 'staff alway', 'staff friendli', 'super friendli', 'sweet potato', 'take care', 'take order', 'take time', 'tast good', 'tast like', 'time come', 'time get', 'time go', 'time went', 'told us', 'took time', 'top notch', 'tri get', 'tri place', 'wait go', 'wait long', 'wait staff', 'wait time', 'walk around', 'want go', 'want tri', 'wast time', 'well done', 'well worth', 'went back', 'would come', 'would definit', 'would give', 'would go', 'would highli', 'would like', 'would never', 'would recommend', 'would say', 'write review', 'year ago', 'year old']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>10</th>\n",
       "      <th>actual</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>amaz</th>\n",
       "      <th>anoth</th>\n",
       "      <th>area</th>\n",
       "      <th>around</th>\n",
       "      <th>...</th>\n",
       "      <th>would give</th>\n",
       "      <th>would go</th>\n",
       "      <th>would highli</th>\n",
       "      <th>would like</th>\n",
       "      <th>would never</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>would say</th>\n",
       "      <th>write review</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>mislabel food visit father nephew first orient...</td>\n",
       "      <td>0.043283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032352</td>\n",
       "      <td>0.034821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>zzwaS0xn1MVEPEf0hNLjew</td>\n",
       "      <td>real bar! great drink price short dilli drinke...</td>\n",
       "      <td>0.012230</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.041137</td>\n",
       "      <td>0.063954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.032798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067163</td>\n",
       "      <td>0.068464</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>zzwhN7x37nyjP0ZM8oiHmw</td>\n",
       "      <td>love place best new bar restaur area limit exc...</td>\n",
       "      <td>0.019056</td>\n",
       "      <td>0.047508</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.081062</td>\n",
       "      <td>0.034068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188593</th>\n",
       "      <td>zzwicjPC9g246MK2M1ZFBA</td>\n",
       "      <td>real good place eat everyon friendli feel welc...</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>0.039952</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05077</td>\n",
       "      <td>0.055729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188594</th>\n",
       "      <td>zzzaIBwimxVej4tY6qFOUQ</td>\n",
       "      <td>guthri hand one best fast food place town neve...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032323</td>\n",
       "      <td>0.038764</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033612</td>\n",
       "      <td>0.047961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "188590  zzvlwkcNR1CCqOPXwuvz2A   \n",
       "188591  zzwaS0xn1MVEPEf0hNLjew   \n",
       "188592  zzwhN7x37nyjP0ZM8oiHmw   \n",
       "188593  zzwicjPC9g246MK2M1ZFBA   \n",
       "188594  zzzaIBwimxVej4tY6qFOUQ   \n",
       "\n",
       "                                                     text        10    actual  \\\n",
       "188590  mislabel food visit father nephew first orient...  0.043283  0.000000   \n",
       "188591  real bar! great drink price short dilli drinke...  0.012230  0.030491   \n",
       "188592  love place best new bar restaur area limit exc...  0.019056  0.047508   \n",
       "188593  real good place eat everyon friendli feel welc...  0.031180  0.013325   \n",
       "188594  guthri hand one best fast food place town neve...  0.000000  0.032323   \n",
       "\n",
       "            also     alway      amaz     anoth      area    around    ...     \\\n",
       "188590  0.032352  0.034821  0.000000  0.000000  0.000000  0.000000    ...      \n",
       "188591  0.041137  0.063954  0.000000  0.005565  0.017342  0.032798    ...      \n",
       "188592  0.064096  0.030661  0.018353  0.008671  0.081062  0.034068    ...      \n",
       "188593  0.039952  0.028667  0.008580  0.012160  0.021053  0.015927    ...      \n",
       "188594  0.038764  0.036506  0.012487  0.035395  0.018384  0.017384    ...      \n",
       "\n",
       "        would give  would go  would highli  would like  would never  \\\n",
       "188590         0.0  0.000000      0.000000     0.00000     0.000000   \n",
       "188591         0.0  0.067163      0.068464     0.00000     0.000000   \n",
       "188592         0.0  0.000000      0.000000     0.00000     0.000000   \n",
       "188593         0.0  0.000000      0.000000     0.05077     0.055729   \n",
       "188594         0.0  0.084994      0.000000     0.00000     0.000000   \n",
       "\n",
       "        would recommend  would say  write review  year ago  year old  \n",
       "188590         0.000000   0.000000           0.0  0.000000       0.0  \n",
       "188591         0.000000   0.000000           0.0  0.000000       0.0  \n",
       "188592         0.112303   0.000000           0.0  0.000000       0.0  \n",
       "188593         0.000000   0.000000           0.0  0.191862       0.0  \n",
       "188594         0.033612   0.047961           0.0  0.039097       0.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "reviews = pd.read_csv('text_transform.csv', low_memory=False)\n",
    "reviews = reviews.drop(['date'], axis=1)\n",
    "reviews = reviews.drop(['text_length'], axis=1)\n",
    "print('done--')\n",
    "reviews['text'] = reviews['text'].astype(str)\n",
    "text_df = reviews.groupby('business_id').agg({'text': ' '.join}).reset_index()\n",
    "\n",
    "print('generate unigram')\n",
    "#generate unigrams\n",
    "v1 = TfidfVectorizer(max_features=200)\n",
    "x1 = v1.fit_transform(text_df['text'])\n",
    "print(v1.get_feature_names())\n",
    "df1 = pd.DataFrame(x1.toarray(), columns=v1.get_feature_names())\n",
    "res = pd.concat([text_df, df1], axis=1)\n",
    "# text_df['tfidf_unigram'] = pd.dataframe(x.toarray())\n",
    "\n",
    "print('generate bigram')\n",
    "#generate bigrams\n",
    "v2 = TfidfVectorizer(ngram_range=(2,2), max_features=200)\n",
    "x2 = v2.fit_transform(text_df['text'])\n",
    "print(v2.get_feature_names())\n",
    "df2 = pd.DataFrame(x2.toarray(), columns=v2.get_feature_names())\n",
    "final_res = pd.concat([res, df2], axis=1)\n",
    "final_res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = final_res.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res.to_csv('unibi200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>...</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>WiFi</th>\n",
       "      <th>Music</th>\n",
       "      <th>Ambience</th>\n",
       "      <th>BusinessParking</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>checkin_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>count_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188588</th>\n",
       "      <td>188588</td>\n",
       "      <td>sMQAZ3DkfrURFoJAyOhjEw</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.551152</td>\n",
       "      <td>-80.021213</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>534.222222</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188589</th>\n",
       "      <td>188589</td>\n",
       "      <td>6hvuCibNS4uECetHb9MCQQ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.534242</td>\n",
       "      <td>-80.019556</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>810.600000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>188590</td>\n",
       "      <td>KleCXFYOmdACcQUvf6_XEg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.378669</td>\n",
       "      <td>-80.724733</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>547</td>\n",
       "      <td>631.846154</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>188591</td>\n",
       "      <td>3_fIsSxN2RBovQ_6EFtLzA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.364366</td>\n",
       "      <td>-80.703454</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>788.789474</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>188592</td>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.118697</td>\n",
       "      <td>-115.154270</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>568.500000</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             business_id  stars   latitude   longitude  \\\n",
       "188588      188588  sMQAZ3DkfrURFoJAyOhjEw    2.5  40.551152  -80.021213   \n",
       "188589      188589  6hvuCibNS4uECetHb9MCQQ    2.0  40.534242  -80.019556   \n",
       "188590      188590  KleCXFYOmdACcQUvf6_XEg    3.0  35.378669  -80.724733   \n",
       "188591      188591  3_fIsSxN2RBovQ_6EFtLzA    4.0  35.364366  -80.703454   \n",
       "188592      188592  NkOvIueadjFUxeCyq_uQEw    4.0  36.118697 -115.154270   \n",
       "\n",
       "        review_count  is_open  Monday  Tuesday  Wednesday        ...          \\\n",
       "188588             9        0       1        1          1        ...           \n",
       "188589             5        1       0        0          0        ...           \n",
       "188590            26        1       1        1          1        ...           \n",
       "188591            19        1       1        1          1        ...           \n",
       "188592             8        1       0        1          1        ...           \n",
       "\n",
       "        Alcohol  WiFi  Music  Ambience  BusinessParking  pos_count  neg_count  \\\n",
       "188588        0     0      0         0                0          4          5   \n",
       "188589        0     0      0         0                0          1          4   \n",
       "188590        0     0      0         0                4         20          6   \n",
       "188591        0     1      0         0                0         17          2   \n",
       "188592        0     0      0         0                4          6          2   \n",
       "\n",
       "        checkin_count  text_length  count_punctuation  \n",
       "188588              3   534.222222           2.000000  \n",
       "188589              0   810.600000           0.200000  \n",
       "188590            547   631.846154           0.769231  \n",
       "188591             58   788.789474           1.000000  \n",
       "188592             14   568.500000           2.375000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_dataset.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.merge(df,final_res,on='business_id').to_csv('D:\\\\features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
