{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('yelp__review.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews[['business_id','text','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5996992</th>\n",
       "      <td>abIF7pw1Hyu-eVW3LwNhyg</td>\n",
       "      <td>I must admit i have had very bad experience he...</td>\n",
       "      <td>2016-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996993</th>\n",
       "      <td>fbLYRHIZAt3q839whhaBUg</td>\n",
       "      <td>Worst service experience in awhile. I usually ...</td>\n",
       "      <td>2017-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996994</th>\n",
       "      <td>b_8jCti0vuouJ_fjZpdmZw</td>\n",
       "      <td>Loved the location, the patio, the service, an...</td>\n",
       "      <td>2018-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996995</th>\n",
       "      <td>wY3dlpLa0BHfDENYAPYuZA</td>\n",
       "      <td>I absolutely hate this place. I would give it ...</td>\n",
       "      <td>2018-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996996</th>\n",
       "      <td>6E4i0NHTRAgpwbbRwZhlnw</td>\n",
       "      <td>The first and the last time I will go there. M...</td>\n",
       "      <td>2018-06-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    business_id  \\\n",
       "5996992  abIF7pw1Hyu-eVW3LwNhyg   \n",
       "5996993  fbLYRHIZAt3q839whhaBUg   \n",
       "5996994  b_8jCti0vuouJ_fjZpdmZw   \n",
       "5996995  wY3dlpLa0BHfDENYAPYuZA   \n",
       "5996996  6E4i0NHTRAgpwbbRwZhlnw   \n",
       "\n",
       "                                                      text        date  \n",
       "5996992  I must admit i have had very bad experience he...  2016-02-29  \n",
       "5996993  Worst service experience in awhile. I usually ...  2017-07-06  \n",
       "5996994  Loved the location, the patio, the service, an...  2018-04-14  \n",
       "5996995  I absolutely hate this place. I would give it ...  2018-04-07  \n",
       "5996996  The first and the last time I will go there. M...  2018-06-07  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STAY AWAY!!! Because I moved this was the closest to my new home. I had my oil and filter changed here about a month ago and after a week my \"oil change\" light came on. My bf mentioned maybe the guy just forgot to reset it so he reset it for me.... Last week it came on again and turned off after a few hours... the next day it was on all day... my bf decided to change the oil and filter himself and showed me that someone wrote on the filter to make sure we know it was changed and the date said JULY 2016!!!!! (see picture posted) This place hasn\\'t changed my filter the both times I\\'ve come to them after telling them I need an oil and filter change. Both times I was also told it will take about 40min.... but only took 10.... did they even check anything else?  And I love how both times They asked if I was paying cash and when I told them cash, both times they\\'re machine/computer was \"down\" so they were unable to print me a receipt...what\\'re you guys doing in there???'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['text'][97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['text_length'] = reviews_df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\deept\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'234 gtudt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "nltk.download('stopwords')\n",
    "def load_stopwords():\n",
    "    return set(stopwords.words(\"english\"))\n",
    "main_count = 0\n",
    "def pre_process(text):\n",
    "    global main_count\n",
    "    main_count+=1\n",
    "    count = 0\n",
    "    porter = nltk.stem.PorterStemmer()\n",
    "    text = text.lower() if text.isalpha() else text\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"?\", \"\") # don't remove ?\n",
    "    remove = remove.replace(\"!\",\"\") # don't remove !\n",
    "    pattern = r\"[{}]\".format(remove)\n",
    "    text = re.sub(pattern, \" \", text)\n",
    "    words = text.split()\n",
    "    stops = load_stopwords()\n",
    "    meaningful_words = [porter.stem(w) for w in words if not w in stops]\n",
    "    if main_count%100000 == 0:\n",
    "        print(main_count)\n",
    "    return \" \".join(meaningful_words)\n",
    "\n",
    "reviews_df['text'] = reviews_df['text'].apply(lambda x: pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STAY AWAY!!! Because I moved this was the closest to my new home. I had my oil and filter changed here about a month ago and after a week my \"oil change\" light came on. My bf mentioned maybe the guy just forgot to reset it so he reset it for me.... Last week it came on again and turned off after a few hours... the next day it was on all day... my bf decided to change the oil and filter himself and showed me that someone wrote on the filter to make sure we know it was changed and the date said JULY 2016!!!!! (see picture posted) This place hasn\\'t changed my filter the both times I\\'ve come to them after telling them I need an oil and filter change. Both times I was also told it will take about 40min.... but only took 10.... did they even check anything else?  And I love how both times They asked if I was paying cash and when I told them cash, both times they\\'re machine/computer was \"down\" so they were unable to print me a receipt...what\\'re you guys doing in there???'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['text'][97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-272895f3c653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreviews_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_length'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreviews_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   2549\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2551\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['count_punctuation'] = reviews_df.text.str.count('\\?|\\!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('punkt')\n",
    "def find_sentiment_score(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    for w in tokens:\n",
    "        if(sia.polarity_scores(w)['compound']) >= 0.5:\n",
    "            pos_count+=1\n",
    "        elif(sia.polarity_scores(w)['compound']) <= -0.5:\n",
    "            neg_count += 1\n",
    "    return pos_count - neg_count\n",
    "# reviews_df['sentiment_score'] = reviews_df['text'].apply(lambda x: find_sentiment_score(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd.Series(' '.join(reviews_df['text']).lower().split()).value_counts()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = feature_names.keys().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# v = TfidfVectorizer(vocabulary=feature_names)\n",
    "# x = v.fit_transform(reviews_df['text'])\n",
    "# # print(v.get_feature_names())\n",
    "# reviews_df['tfidf'] = list(x.toarray())\n",
    "# reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = reviews_df.groupby(reviews_df.business_id).agg(lambda x: ' '.join(x.unique())).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(vocabulary=feature_names)\n",
    "x = v.fit_transform(text_df['text'])\n",
    "print(v.get_feature_names())\n",
    "text_df['tfidf_unigram'] = list(x.toarray())\n",
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['sentiment_score'] = text_df['text'].apply(lambda x: find_sentiment_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.loc[text_df['business_id'] == '7wHLFohwCw8l6WS-feLjeg', 'tfidf'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df[0:2]\n",
    "reviews_df.loc[reviews_df['business_id'] == '7wHLFohwCw8l6WS-feLjeg', 'text_length'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = reviews_df.groupby('business_id').agg({'text_length': 'mean', 'count_punctuation': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.loc[text_df['business_id'] == '7wHLFohwCw8l6WS-feLjeg', 'text_length'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_unigram = pd.merge(df_1, text_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_unigram[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_unigram.to_csv('unigram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "n_grams = vectorizer.fit_transform(reviews_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "count_values = n_grams.toarray().sum(axis=0)\n",
    "counts = sorted([(count_values[i],k) for k,i in vocab.items()], reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(x[1] for x in counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(ngram_range=(2,2), max_features=500)\n",
    "x = v.fit_transform(text_df['text'])\n",
    "# print(v.get_feature_names())\n",
    "text_df['tfidf_bigram'] = list(x.toarray())\n",
    "text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_bigram = pd.merge(df_1, text_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_bigram.to_csv('bigram.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
